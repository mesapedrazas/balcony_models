{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import re\n",
    "import string\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from utils import (\n",
    "    drop_spam_rows,\n",
    "    remove_digits,\n",
    "    remove_prefixed_words,\n",
    "    contract_spaces,\n",
    "    remove_single_characters,\n",
    "    remove_special_characters,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load spaCy Spanish trained pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    sp = spacy.load(\"es_core_news_sm\")\n",
    "except OSError:\n",
    "    !python3 -m spacy download es_core_news_sm\n",
    "    sp = spacy.load(\"es_core_news_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"data/balcones_2020.csv\"\n",
    "dataset = pd.read_csv(dataset_path)\n",
    "texts = dataset[\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_texts = [\n",
    "    \"El Magazin del Balcón Segoviano\",\n",
    "    \"Viva María Auxiliadora\",\n",
    "    \"Italianos cantan 'Bella Ciao' en sus balcones por los 75 años de la caída del fascismo\",\n",
    "]\n",
    "texts = drop_spam_rows(text_series=texts, spam_messages=spam_texts)\n",
    "texts = texts[texts.duplicated() == False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "PUNCTUATION_MARKS = string.punctuation + \"¿\" + \"¡\" + \"...\" + \"…\" + \" \"\n",
    "STOP_WORDS = nltk.corpus.stopwords.words(\"spanish\")\n",
    "UNDESIRED_WORDS = [\n",
    "    \"balcón\",\n",
    "    \"balcones\",\n",
    "    \"balcon\",\n",
    "    \"si\",\n",
    "    \"haber\",\n",
    "    \"ser\",\n",
    "    \"quedateencasa\",\n",
    "    \"yomequedoencasa\",\n",
    "    # \"toca\"\n",
    "]\n",
    "UNDESIRED_PREFIXES = [\"@\", \"#\", \"http\", \"jaj\", \"xd\", \"xD\", \"XD\"]\n",
    "\n",
    "\n",
    "def tokenize(text):\n",
    "    \"\"\"Get tokenized text.\"\"\"\n",
    "    return \" \".join(\n",
    "        [\n",
    "            token.lemma_ for token in sp(text)\n",
    "            if token.text not in PUNCTUATION_MARKS\n",
    "            and token.text not in STOP_WORDS + UNDESIRED_WORDS\n",
    "        ]\n",
    "    )\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Apply transformations to text.\"\"\"\n",
    "    text = text.lower()\n",
    "    for prefix in UNDESIRED_PREFIXES:\n",
    "            text = remove_prefixed_words(prefix, text)\n",
    "    text = remove_special_characters(text)\n",
    "    text = remove_single_characters(text)\n",
    "    text = remove_digits(text)\n",
    "    text = contract_spaces(text)\n",
    "    return tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_preprocessed = texts.apply(lambda x: preprocess_text(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = TfidfVectorizer(\n",
    "    stop_words=(STOP_WORDS),\n",
    "    min_df=3,\n",
    "    max_df=0.85,\n",
    "    ngram_range=(1, 3)\n",
    ")\n",
    "X = tf.fit_transform(texts_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = tf.get_feature_names_out()\n",
    "words = np.array(tf.get_feature_names_out())\n",
    "matrix = pd.DataFrame(X.toarray(), columns=feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NMF(n_components=20, random_state=42)\n",
    "nmf_output = model.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "components_df = pd.DataFrame(model.components_, columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abajo</th>\n",
       "      <th>abascal</th>\n",
       "      <th>abeja</th>\n",
       "      <th>abierto</th>\n",
       "      <th>abrazar</th>\n",
       "      <th>abrazarno</th>\n",
       "      <th>abrazo</th>\n",
       "      <th>abrazo enorme</th>\n",
       "      <th>abrigo</th>\n",
       "      <th>abril</th>\n",
       "      <th>...</th>\n",
       "      <th>único dar</th>\n",
       "      <th>único hacer</th>\n",
       "      <th>único momento</th>\n",
       "      <th>único poder</th>\n",
       "      <th>único sitio</th>\n",
       "      <th>único vecino</th>\n",
       "      <th>útil</th>\n",
       "      <th>útil habitación</th>\n",
       "      <th>útil habitación baño</th>\n",
       "      <th>útil habitación baños</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001748</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001892</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.042629</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007739</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005213</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000939</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003010</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006086</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019478</td>\n",
       "      <td>0.005007</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.028219</td>\n",
       "      <td>0.007088</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.053762</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000899</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003944</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000756</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001281</td>\n",
       "      <td>0.000784</td>\n",
       "      <td>0.000584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005713</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001285</td>\n",
       "      <td>0.008616</td>\n",
       "      <td>0.000682</td>\n",
       "      <td>0.001852</td>\n",
       "      <td>0.020038</td>\n",
       "      <td>0.002942</td>\n",
       "      <td>0.002132</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014779</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004799</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 6813 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      abajo  abascal     abeja   abierto   abrazar  abrazarno    abrazo  \\\n",
       "0  0.001748      0.0  0.001892  0.000000  0.000000   0.000000  0.000000   \n",
       "1  0.042629      0.0  0.000000  0.000000  0.000000   0.000000  0.000000   \n",
       "2  0.000000      0.0  0.000000  0.000000  0.000939   0.000000  0.000000   \n",
       "3  0.000000      0.0  0.000000  0.019478  0.005007   0.000135  0.028219   \n",
       "4  0.005713      0.0  0.001285  0.008616  0.000682   0.001852  0.020038   \n",
       "\n",
       "   abrazo enorme    abrigo     abril  ...  único dar  único hacer  \\\n",
       "0       0.000000  0.000000  0.000000  ...   0.000000     0.000000   \n",
       "1       0.000000  0.000000  0.000000  ...   0.000000     0.007739   \n",
       "2       0.000000  0.000000  0.000000  ...   0.003010     0.000000   \n",
       "3       0.007088  0.000000  0.053762  ...   0.000899     0.000000   \n",
       "4       0.002942  0.002132  0.000000  ...   0.000000     0.014779   \n",
       "\n",
       "   único momento  único poder  único sitio  único vecino      útil  \\\n",
       "0       0.008999     0.000000     0.000000           0.0  0.000000   \n",
       "1       0.000000     0.005213     0.000000           0.0  0.000000   \n",
       "2       0.000130     0.000000     0.000000           0.0  0.006086   \n",
       "3       0.003944     0.000000     0.000756           0.0  0.000000   \n",
       "4       0.000000     0.004799     0.000000           0.0  0.000000   \n",
       "\n",
       "   útil habitación  útil habitación baño  útil habitación baños  \n",
       "0         0.000000              0.000000               0.000000  \n",
       "1         0.000000              0.000000               0.000000  \n",
       "2         0.000000              0.000000               0.000000  \n",
       "3         0.001281              0.000784               0.000584  \n",
       "4         0.000000              0.000000               0.000000  \n",
       "\n",
       "[5 rows x 6813 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "components_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For topic 0 the words with the highest value are:\n",
      "salir             4.449236\n",
      "salir aplaudir    0.692522\n",
      "poder salir       0.357594\n",
      "ir salir          0.348252\n",
      "salir cantar      0.242864\n",
      "hoy salir         0.191526\n",
      "hora salir        0.182254\n",
      "gente salir       0.165179\n",
      "salir calle       0.164909\n",
      "salir día         0.140047\n",
      "Name: 0, dtype: float64\n",
      "\n",
      "\n",
      "For topic 1 the words with the highest value are:\n",
      "tirar            3.200566\n",
      "ir tirar         0.198088\n",
      "querer tirar     0.176858\n",
      "querer           0.139755\n",
      "poder tirar      0.137848\n",
      "dos              0.093807\n",
      "cuarentena       0.090272\n",
      "gana tirar       0.085498\n",
      "tirar petardo    0.082287\n",
      "petardo          0.078579\n",
      "Name: 1, dtype: float64\n",
      "\n",
      "\n",
      "For topic 2 the words with the highest value are:\n",
      "aplaudir              2.745884\n",
      "salir aplaudir        0.932866\n",
      "luego                 0.376544\n",
      "sanitario             0.310074\n",
      "sanidad               0.192477\n",
      "aplaudir sanitario    0.183828\n",
      "seguro                0.159897\n",
      "público               0.142370\n",
      "gente aplaudir        0.114769\n",
      "sanidad público       0.112827\n",
      "Name: 2, dtype: float64\n",
      "\n",
      "\n",
      "For topic 3 the words with the highest value are:\n",
      "día               2.302103\n",
      "cada              0.532893\n",
      "cada día          0.447221\n",
      "buen              0.406490\n",
      "buen día          0.360504\n",
      "menos             0.171964\n",
      "aplauso           0.168933\n",
      "día cuarentena    0.152087\n",
      "cuarentena        0.141989\n",
      "confinamiento     0.131967\n",
      "Name: 3, dtype: float64\n",
      "\n",
      "\n",
      "For topic 4 the words with the highest value are:\n",
      "hacer          1.921320\n",
      "cosa           0.113451\n",
      "poder hacer    0.100667\n",
      "mismo          0.087945\n",
      "cuarentena     0.081522\n",
      "hacer salir    0.076016\n",
      "salir hacer    0.076013\n",
      "año            0.075605\n",
      "saber          0.075282\n",
      "ir hacer       0.074203\n",
      "Name: 4, dtype: float64\n",
      "\n",
      "\n",
      "For topic 5 the words with the highest value are:\n",
      "poner           2.096176\n",
      "música          0.849296\n",
      "poner música    0.647533\n",
      "altavoz         0.155584\n",
      "ir poner        0.147522\n",
      "poner himno     0.134445\n",
      "vecino poner    0.116073\n",
      "himno           0.105873\n",
      "salir poner     0.102551\n",
      "canción         0.097554\n",
      "Name: 5, dtype: float64\n",
      "\n",
      "\n",
      "For topic 6 the words with the highest value are:\n",
      "ver            2.217996\n",
      "pasar          0.132443\n",
      "así            0.102323\n",
      "bien           0.097407\n",
      "niño           0.093111\n",
      "ver ventana    0.092251\n",
      "ir ver         0.091027\n",
      "ver gente      0.089626\n",
      "padre          0.083623\n",
      "dos            0.083157\n",
      "Name: 6, dtype: float64\n",
      "\n",
      "\n",
      "For topic 7 the words with the highest value are:\n",
      "casa           2.295444\n",
      "quedar         0.320612\n",
      "quedar casa    0.184593\n",
      "año            0.154606\n",
      "salir casa     0.117238\n",
      "sal            0.106521\n",
      "llegar         0.097282\n",
      "puta           0.097166\n",
      "semana         0.084751\n",
      "santo          0.083672\n",
      "Name: 7, dtype: float64\n",
      "\n",
      "\n",
      "For topic 8 the words with the highest value are:\n",
      "hoy          2.525923\n",
      "tocar        0.269456\n",
      "hoy tocar    0.219587\n",
      "hoy salir    0.176597\n",
      "aplauso      0.160196\n",
      "gracias      0.138646\n",
      "barrio       0.127484\n",
      "bonito       0.110868\n",
      "sonar        0.106016\n",
      "salir hoy    0.104638\n",
      "Name: 8, dtype: float64\n",
      "\n",
      "\n",
      "For topic 9 the words with the highest value are:\n",
      "ir          2.095654\n",
      "ir salir    0.260969\n",
      "decir       0.217490\n",
      "ir tirar    0.138668\n",
      "ir poner    0.104430\n",
      "ir ver      0.100683\n",
      "pasar       0.099945\n",
      "ir hacer    0.092095\n",
      "ir mano     0.084871\n",
      "mano        0.080081\n",
      "Name: 9, dtype: float64\n",
      "\n",
      "\n",
      "For topic 10 the words with the highest value are:\n",
      "dar          1.952349\n",
      "sol          0.329056\n",
      "vida         0.193807\n",
      "ahora        0.186826\n",
      "dar sol      0.145833\n",
      "tener        0.145225\n",
      "salir dar    0.120357\n",
      "cuenta       0.114117\n",
      "dar vida     0.112993\n",
      "gracia       0.111502\n",
      "Name: 10, dtype: float64\n",
      "\n",
      "\n",
      "For topic 11 the words with the highest value are:\n",
      "ventana             2.402498\n",
      "terraza             0.367199\n",
      "ver ventana         0.188275\n",
      "vía                 0.178576\n",
      "noche               0.171658\n",
      "domingo             0.147598\n",
      "terraza ventana     0.144225\n",
      "salir ventana       0.138802\n",
      "ventana aplaudir    0.137883\n",
      "ventana terraza     0.116081\n",
      "Name: 11, dtype: float64\n",
      "\n",
      "\n",
      "For topic 12 the words with the highest value are:\n",
      "policía    2.149495\n",
      "vía        0.214717\n",
      "decir      0.123183\n",
      "esperar    0.118963\n",
      "llamar     0.095164\n",
      "creer      0.093471\n",
      "niño       0.088329\n",
      "peor       0.083873\n",
      "ahora      0.076151\n",
      "fin        0.069656\n",
      "Name: 12, dtype: float64\n",
      "\n",
      "\n",
      "For topic 13 the words with the highest value are:\n",
      "vecino          2.073532\n",
      "cantar          0.864353\n",
      "tocar           0.340407\n",
      "fiesta          0.254382\n",
      "cuarentena      0.212866\n",
      "bailar          0.163954\n",
      "salir cantar    0.153347\n",
      "montar          0.143562\n",
      "así             0.140499\n",
      "cumpleaños      0.129430\n",
      "Name: 13, dtype: float64\n",
      "\n",
      "\n",
      "For topic 14 the words with the highest value are:\n",
      "mañana          2.021857\n",
      "escuchar        0.138156\n",
      "vez             0.108091\n",
      "mañana poner    0.107224\n",
      "tarde           0.088356\n",
      "hoy mañana      0.087407\n",
      "llevar          0.084610\n",
      "mismo           0.084393\n",
      "bien            0.076654\n",
      "mañana ir       0.069701\n",
      "Name: 14, dtype: float64\n",
      "\n",
      "\n",
      "For topic 15 the words with the highest value are:\n",
      "poder          3.192115\n",
      "poder salir    0.765519\n",
      "sol            0.504385\n",
      "tomar          0.353369\n",
      "poder hacer    0.289518\n",
      "esperar        0.235046\n",
      "tomar sol      0.211048\n",
      "poder tirar    0.196402\n",
      "decir          0.183606\n",
      "disfrutar      0.175679\n",
      "Name: 15, dtype: float64\n",
      "\n",
      "\n",
      "For topic 16 the words with the highest value are:\n",
      "foto                           0.751489\n",
      "acabar                         0.624343\n",
      "segoviano                      0.573682\n",
      "periódico digital              0.561092\n",
      "segoviano periódico            0.561092\n",
      "segoviano periódico digital    0.561092\n",
      "periódico                      0.560448\n",
      "digital                        0.542480\n",
      "publicar foto                  0.517874\n",
      "publicar                       0.513755\n",
      "Name: 16, dtype: float64\n",
      "\n",
      "\n",
      "For topic 17 the words with the highest value are:\n",
      "gente             2.413315\n",
      "calle             1.494665\n",
      "gente salir       0.232048\n",
      "mismo             0.223259\n",
      "pasar             0.195754\n",
      "ver gente         0.194875\n",
      "gente aplaudir    0.191635\n",
      "gente calle       0.191539\n",
      "gritar            0.181267\n",
      "empezar           0.166460\n",
      "Name: 17, dtype: float64\n",
      "\n",
      "\n",
      "For topic 18 the words with the highest value are:\n",
      "españa            1.377938\n",
      "bandera           0.816016\n",
      "bandera españa    0.451129\n",
      "himno             0.357038\n",
      "negro             0.343519\n",
      "crespón           0.317979\n",
      "crespón negro     0.304807\n",
      "aplauso           0.278843\n",
      "fallecido         0.235022\n",
      "señal             0.209537\n",
      "Name: 18, dtype: float64\n",
      "\n",
      "\n",
      "For topic 19 the words with the highest value are:\n",
      "spain                1.465504\n",
      "madrid               1.323032\n",
      "madrid spain         1.013681\n",
      "cuarentena           0.229438\n",
      "vez                  0.134476\n",
      "cada                 0.118951\n",
      "cada vez             0.118173\n",
      "ligar                0.107246\n",
      "semana               0.107225\n",
      "cuarentena madrid    0.093744\n",
      "Name: 19, dtype: float64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for topic in range(components_df.shape[0]):\n",
    "    tmp = components_df.iloc[topic]\n",
    "    print(f'For topic {topic} the words with the highest value are:')\n",
    "    print(tmp.nlargest(10))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('balcony-models')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "10d25286d6d126a35d4ad4188b71370e978556e18398277650caecac83008c5a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
