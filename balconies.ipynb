{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c0f3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import re\n",
    "import string\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from utils import (\n",
    "    drop_spam_rows,\n",
    "    remove_digits,\n",
    "    remove_prefixed_words,\n",
    "    contract_spaces,\n",
    "    remove_single_characters,\n",
    "    remove_special_characters,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd3ed8f",
   "metadata": {},
   "source": [
    "# Load spaCy Spanish trained pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a07bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    sp = spacy.load(\"es_core_news_sm\")\n",
    "except OSError:\n",
    "    !python3 -m spacy download es_core_news_sm\n",
    "    sp = spacy.load(\"es_core_news_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0babe9",
   "metadata": {},
   "source": [
    "# Load texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2fcde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"dataset_balcones.csv\"\n",
    "dataset = pd.read_csv(dataset_path, sep=\";\")\n",
    "texts = dataset[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968642eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecbbfe9",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f878e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "PUNCTUATION_MARKS = string.punctuation + \"¿\" + \"¡\" + \"...\" + \"…\" + \" \"\n",
    "\n",
    "UNDESIRED_WORDS = [\n",
    "    \"balcón\",\n",
    "    \"balcones\",\n",
    "    \"balcon\",\n",
    "    \"si\",\n",
    "    \"haber\",\n",
    "    \"ser\",\n",
    "    \"quedateencasa\",\n",
    "    \"yomequedoencasa\",\n",
    "    \"tirar\"\n",
    "]\n",
    "\n",
    "STOP_WORDS = nltk.corpus.stopwords.words(\"spanish\") + UNDESIRED_WORDS\n",
    "\n",
    "UNDESIRED_PREFIXES = [\"@\", \"#\", \"http\", \"jaj\", \"xd\", \"xD\", \"XD\", \"pic\", \"twitter\", \"tw\", \"com\"]\n",
    "\n",
    "\n",
    "def tokenize(text):\n",
    "    \"\"\"Get tokenized text.\"\"\"\n",
    "    return \" \".join(\n",
    "        [\n",
    "            token.lemma_ for token in sp(text)\n",
    "            if token.text not in PUNCTUATION_MARKS\n",
    "            and token.text not in STOP_WORDS\n",
    "        ]\n",
    "    )\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Apply transformations to text.\"\"\"\n",
    "    text = text.lower()\n",
    "    for prefix in UNDESIRED_PREFIXES:\n",
    "            text = remove_prefixed_words(prefix, text)\n",
    "    text = remove_special_characters(text)\n",
    "    text = remove_single_characters(text)\n",
    "    text = remove_digits(text)\n",
    "    text = contract_spaces(text)\n",
    "    return tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d6fd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_preprocessed = texts.apply(lambda x: preprocess_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70cfad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_preprocessed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad85b446",
   "metadata": {},
   "source": [
    "# TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba6e8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = TfidfVectorizer(\n",
    "    stop_words=(STOP_WORDS),\n",
    "    max_features=None,\n",
    "    min_df=3,\n",
    "    max_df=0.85,\n",
    "    ngram_range=(1, 3)\n",
    ")\n",
    "X = tf.fit_transform(texts_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c6b228",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = tf.get_feature_names_out()\n",
    "words = np.array(tf.get_feature_names_out())\n",
    "matrix = pd.DataFrame(X.toarray(), columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbfba21",
   "metadata": {},
   "outputs": [],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7f4bac",
   "metadata": {},
   "source": [
    "# NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee6c01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NMF(n_components=6, random_state=42, max_iter=1000)\n",
    "nmf_output = model.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51eba2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "components_df = pd.DataFrame(model.components_, columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2488139",
   "metadata": {},
   "outputs": [],
   "source": [
    "components_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78053117",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for topic in range(components_df.shape[0]):\n",
    "    tmp = components_df.iloc[topic]\n",
    "    print(f'For topic {topic} the words with the highest value are:')\n",
    "    print(tmp.nlargest(15))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485a1ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11184165",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56f1b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "components_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad247b1",
   "metadata": {},
   "source": [
    "# Create dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0c5e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# column names\n",
    "topicnames = ['Topic_' + str(i) for i in range(model.n_components)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fb016d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe\n",
    "dataset_tweet_topic = pd.DataFrame(np.round(nmf_output, 3), columns=topicnames)\n",
    "\n",
    "# dominant topic\n",
    "dataset_tweet_topic['dominant_topic'] = np.argmax(dataset_tweet_topic.values, axis=1)\n",
    "dataset_tweet_topic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5881f2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_names = {\n",
    "    0: \"Activities\",\n",
    "    1: \"Tribute\",\n",
    "    2: \"Routines\",\n",
    "    3: \"Desires\",\n",
    "    4: \"Communication\",\n",
    "    5: \"Social Control\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c92f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_tweet_topic.category = dataset_tweet_topic.dominant_topic.replace(topic_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0067ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "g= sns.countplot(x = dataset_tweet_topic.category)\n",
    "g.set_xticklabels(g.get_xticklabels(), rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f130ac2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.concat([dataset_tweet_topic.category, dataset.text], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2096da",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f841c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_df.to_csv(\"final_df.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50701c1d",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8397e776",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=3)\n",
    "result = pca.fit_transform(nmf_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ba35b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(9, 9))\n",
    "sns.scatterplot(\n",
    "    x=result[:, 1], \n",
    "    y=result[:, 0], \n",
    "    hue=dataset_tweet_topic.category, \n",
    "    palette=sns.color_palette(\"tab20_r\", 6),\n",
    "#     style=df_tweet_topic.dominant_topic,\n",
    "    s=100\n",
    ")\n",
    "plt.xlim(-0.1, 0.22)\n",
    "plt.ylim(-0.10, 0.29)\n",
    "plt.xlabel(\"Component 1\")\n",
    "plt.ylabel(\"Component 2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986e20f0",
   "metadata": {},
   "source": [
    "# Tweets by topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a472eedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#consult the tweets associated with each topic\n",
    "topic = \"Routines\"\n",
    "\n",
    "for n in final_df[final_df.dominant_topic==topic].index:\n",
    "    print(final_df.text.iloc[n] + \"\\n\")"
   ]
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
