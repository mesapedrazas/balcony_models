{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import re\n",
    "import string\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from utils import (\n",
    "    drop_spam_rows,\n",
    "    remove_digits,\n",
    "    remove_prefixed_words,\n",
    "    contract_spaces,\n",
    "    remove_single_characters,\n",
    "    remove_special_characters,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load spaCy Spanish trained pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    sp = spacy.load(\"es_core_news_sm\")\n",
    "except OSError:\n",
    "    !python3 -m spacy download es_core_news_sm\n",
    "    sp = spacy.load(\"es_core_news_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"data/balcones_2020.csv\"\n",
    "dataset = pd.read_csv(dataset_path)\n",
    "texts = dataset[\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_texts = [\n",
    "    \"El Magazin del Balcón Segoviano\",\n",
    "    \"Viva María Auxiliadora\",\n",
    "    \"Italianos cantan 'Bella Ciao' en sus balcones por los 75 años de la caída del fascismo\",\n",
    "]\n",
    "texts = drop_spam_rows(text_series=texts, spam_messages=spam_texts)\n",
    "texts = texts[texts.duplicated() == False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PUNCTUATION_MARKS = string.punctuation + \"¿\" + \"¡\" + \"...\" + \"…\" + \" \"\n",
    "STOP_WORDS = nltk.corpus.stopwords.words(\"spanish\")\n",
    "UNDESIRED_WORDS = [\n",
    "    \"balcón\",\n",
    "    \"balcones\",\n",
    "    \"balcon\",\n",
    "    \"si\",\n",
    "    \"haber\",\n",
    "    \"ser\",\n",
    "    \"quedateencasa\",\n",
    "    \"yomequedoencasa\",\n",
    "    # \"toca\"\n",
    "]\n",
    "UNDESIRED_PREFIXES = [\"@\", \"#\", \"http\", \"jaj\", \"xd\", \"xD\", \"XD\"]\n",
    "\n",
    "\n",
    "def tokenize(text):\n",
    "    \"\"\"Get tokenized text.\"\"\"\n",
    "    return \" \".join(\n",
    "        [\n",
    "            token.lemma_ for token in sp(text)\n",
    "            if token.text not in PUNCTUATION_MARKS\n",
    "            and token.text not in STOP_WORDS + UNDESIRED_WORDS\n",
    "        ]\n",
    "    )\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Apply transformations to text.\"\"\"\n",
    "    text = text.lower()\n",
    "    for prefix in UNDESIRED_PREFIXES:\n",
    "            text = remove_prefixed_words(prefix, text)\n",
    "    text = remove_special_characters(text)\n",
    "    text = remove_single_characters(text)\n",
    "    text = remove_digits(text)\n",
    "    text = contract_spaces(text)\n",
    "    return tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_preprocessed = texts.apply(lambda x: preprocess_text(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = TfidfVectorizer(\n",
    "    stop_words=(STOP_WORDS),\n",
    "    min_df=3,\n",
    "    max_df=0.85,\n",
    "    ngram_range=(1, 3)\n",
    ")\n",
    "X = tf.fit_transform(texts_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = tf.get_feature_names_out()\n",
    "words = np.array(tf.get_feature_names_out())\n",
    "matrix = pd.DataFrame(X.toarray(), columns=feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robert/miniconda3/envs/balcony-models/lib/python3.7/site-packages/sklearn/decomposition/_nmf.py:294: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "model = NMF(n_components=20, random_state=42)\n",
    "nmf_output = model.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "components_df = pd.DataFrame(model.components_, columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abajo</th>\n",
       "      <th>abascal</th>\n",
       "      <th>abeja</th>\n",
       "      <th>abierto</th>\n",
       "      <th>abrazar</th>\n",
       "      <th>abrazarno</th>\n",
       "      <th>abrazo</th>\n",
       "      <th>abrazo enorme</th>\n",
       "      <th>abrigo</th>\n",
       "      <th>abril</th>\n",
       "      <th>...</th>\n",
       "      <th>único ciudadano español</th>\n",
       "      <th>único dar</th>\n",
       "      <th>único hacer</th>\n",
       "      <th>único momento</th>\n",
       "      <th>único poder</th>\n",
       "      <th>único sitio</th>\n",
       "      <th>único vecino</th>\n",
       "      <th>útil</th>\n",
       "      <th>útil habitación</th>\n",
       "      <th>útil habitación baño</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.015414</td>\n",
       "      <td>0.01877</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032558</td>\n",
       "      <td>0.030390</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001559</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003406</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002779</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005598</td>\n",
       "      <td>0.01262</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002357</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000919</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004443</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019322</td>\n",
       "      <td>0.004857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025627</td>\n",
       "      <td>0.006686</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050855</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001201</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004228</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001353</td>\n",
       "      <td>0.001353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.044990</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008579</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006017</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.008066</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.001342</td>\n",
       "      <td>0.010490</td>\n",
       "      <td>0.001187</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>0.021850</td>\n",
       "      <td>0.003197</td>\n",
       "      <td>0.002265</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015203</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.005508</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 6795 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      abajo  abascal     abeja   abierto   abrazar  abrazarno    abrazo  \\\n",
       "0  0.015414  0.01877  0.000000  0.032558  0.030390   0.000000  0.001559   \n",
       "1  0.002357  0.00000  0.000919  0.000000  0.000000   0.000000  0.000000   \n",
       "2  0.000000  0.00000  0.000000  0.019322  0.004857   0.000000  0.025627   \n",
       "3  0.044990  0.00000  0.000000  0.000000  0.000000   0.000000  0.000000   \n",
       "4  0.008066  0.00000  0.001342  0.010490  0.001187   0.001779  0.021850   \n",
       "\n",
       "   abrazo enorme    abrigo     abril  ...  único ciudadano español  único dar  \\\n",
       "0       0.000000  0.000000  0.000000  ...                      0.0   0.003406   \n",
       "1       0.000000  0.000000  0.000000  ...                      0.0   0.000000   \n",
       "2       0.006686  0.000000  0.050855  ...                      0.0   0.001201   \n",
       "3       0.000000  0.000000  0.000000  ...                      0.0   0.000000   \n",
       "4       0.003197  0.002265  0.000000  ...                      0.0   0.000000   \n",
       "\n",
       "   único hacer  único momento  único poder  único sitio  único vecino  útil  \\\n",
       "0     0.000000       0.002779     0.000000     0.005598       0.01262   0.0   \n",
       "1     0.000000       0.004443     0.000000     0.000000       0.00000   0.0   \n",
       "2     0.000000       0.004228     0.000000     0.000250       0.00000   0.0   \n",
       "3     0.008579       0.000000     0.006017     0.000000       0.00000   0.0   \n",
       "4     0.015203       0.000096     0.005508     0.000000       0.00000   0.0   \n",
       "\n",
       "   útil habitación  útil habitación baño  \n",
       "0         0.000000              0.000000  \n",
       "1         0.000000              0.000000  \n",
       "2         0.001353              0.001353  \n",
       "3         0.000000              0.000000  \n",
       "4         0.000000              0.000000  \n",
       "\n",
       "[5 rows x 6795 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "components_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For topic 0 the words with the highest value are:\n",
      "ver            5.212463\n",
      "pasar          0.309076\n",
      "bien           0.266964\n",
      "ver ventana    0.225645\n",
      "ver gente      0.216513\n",
      "asomar         0.210843\n",
      "dos            0.207527\n",
      "ir ver         0.205509\n",
      "niño           0.204307\n",
      "padre          0.204028\n",
      "Name: 0, dtype: float64\n",
      "\n",
      "\n",
      "For topic 1 the words with the highest value are:\n",
      "salir             2.174047\n",
      "salir aplaudir    0.335268\n",
      "poder salir       0.173513\n",
      "ir salir          0.161624\n",
      "salir cantar      0.100104\n",
      "hoy salir         0.090644\n",
      "salir calle       0.078632\n",
      "gente salir       0.077538\n",
      "hora salir        0.072491\n",
      "salir casa        0.065366\n",
      "Name: 1, dtype: float64\n",
      "\n",
      "\n",
      "For topic 2 the words with the highest value are:\n",
      "día               2.246444\n",
      "cada              0.527377\n",
      "cada día          0.451089\n",
      "buen              0.373161\n",
      "buen día          0.333935\n",
      "menos             0.154873\n",
      "día cuarentena    0.147087\n",
      "aplauso           0.146930\n",
      "confinamiento     0.125069\n",
      "cuarentena        0.124725\n",
      "Name: 2, dtype: float64\n",
      "\n",
      "\n",
      "For topic 3 the words with the highest value are:\n",
      "tirar           2.548991\n",
      "ir tirar        0.234984\n",
      "querer tirar    0.186173\n",
      "poder tirar     0.171910\n",
      "querer          0.164483\n",
      "gana tirar      0.104330\n",
      "pa              0.100908\n",
      "gana            0.099046\n",
      "pa tirar        0.083603\n",
      "pensar          0.083352\n",
      "Name: 3, dtype: float64\n",
      "\n",
      "\n",
      "For topic 4 the words with the highest value are:\n",
      "hacer           2.041159\n",
      "cosa            0.116601\n",
      "poder hacer     0.110543\n",
      "mismo           0.090480\n",
      "salir hacer     0.080521\n",
      "ir hacer        0.078824\n",
      "cuarentena      0.077829\n",
      "saber           0.077825\n",
      "hacer fiesta    0.077396\n",
      "hacer salir     0.077301\n",
      "Name: 4, dtype: float64\n",
      "\n",
      "\n",
      "For topic 5 the words with the highest value are:\n",
      "poner           1.900292\n",
      "música          0.647701\n",
      "poner música    0.512450\n",
      "ir poner        0.122342\n",
      "altavoz         0.118840\n",
      "tusa            0.111813\n",
      "poner himno     0.111094\n",
      "vecino poner    0.103621\n",
      "poner tusa      0.097702\n",
      "poder poner     0.086209\n",
      "Name: 5, dtype: float64\n",
      "\n",
      "\n",
      "For topic 6 the words with the highest value are:\n",
      "aplaudir              2.927391\n",
      "salir aplaudir        1.077510\n",
      "luego                 0.409913\n",
      "sanitario             0.354396\n",
      "aplaudir sanitario    0.207451\n",
      "sanidad               0.182044\n",
      "seguro                0.168313\n",
      "hora                  0.150123\n",
      "público               0.146195\n",
      "salgo                 0.143399\n",
      "Name: 6, dtype: float64\n",
      "\n",
      "\n",
      "For topic 7 the words with the highest value are:\n",
      "casa           2.103667\n",
      "quedar         0.159146\n",
      "año            0.153780\n",
      "salir casa     0.108442\n",
      "llegar         0.097076\n",
      "puta           0.092827\n",
      "quedar casa    0.091527\n",
      "quedo          0.090918\n",
      "semana         0.086316\n",
      "santo          0.083641\n",
      "Name: 7, dtype: float64\n",
      "\n",
      "\n",
      "For topic 8 the words with the highest value are:\n",
      "hoy          2.208906\n",
      "tocar        0.244458\n",
      "hoy tocar    0.197504\n",
      "hoy salir    0.164722\n",
      "aplauso      0.136998\n",
      "barrio       0.107309\n",
      "bonito       0.099853\n",
      "gracias      0.091044\n",
      "salir hoy    0.089870\n",
      "sonar        0.089362\n",
      "Name: 8, dtype: float64\n",
      "\n",
      "\n",
      "For topic 9 the words with the highest value are:\n",
      "ir          2.167036\n",
      "ir salir    0.278450\n",
      "decir       0.222732\n",
      "ir tirar    0.143439\n",
      "ir poner    0.108953\n",
      "ir ver      0.106727\n",
      "ir hacer    0.096899\n",
      "pasar       0.094430\n",
      "ir mano     0.090402\n",
      "mano        0.085350\n",
      "Name: 9, dtype: float64\n",
      "\n",
      "\n",
      "For topic 10 the words with the highest value are:\n",
      "dar           2.121082\n",
      "ahora         0.192526\n",
      "vida          0.187775\n",
      "tener         0.157368\n",
      "sol           0.156158\n",
      "cuenta        0.149267\n",
      "gracia        0.146288\n",
      "dar sol       0.136573\n",
      "salir dar     0.136284\n",
      "dar cuenta    0.135617\n",
      "Name: 10, dtype: float64\n",
      "\n",
      "\n",
      "For topic 11 the words with the highest value are:\n",
      "españa            1.567896\n",
      "bandera           0.880883\n",
      "bandera españa    0.490840\n",
      "himno             0.394426\n",
      "negro             0.361078\n",
      "crespón           0.334532\n",
      "crespón negro     0.320523\n",
      "aplauso           0.292079\n",
      "fallecido         0.237769\n",
      "señal             0.213265\n",
      "Name: 11, dtype: float64\n",
      "\n",
      "\n",
      "For topic 12 the words with the highest value are:\n",
      "policía     2.159416\n",
      "vía         0.225277\n",
      "decir       0.118197\n",
      "esperar     0.112981\n",
      "llamar      0.092895\n",
      "creer       0.092875\n",
      "peor        0.087242\n",
      "niño        0.083166\n",
      "ahora       0.073216\n",
      "denuncia    0.071208\n",
      "Name: 12, dtype: float64\n",
      "\n",
      "\n",
      "For topic 13 the words with the highest value are:\n",
      "vecino          1.945448\n",
      "cantar          1.005242\n",
      "tocar           0.363596\n",
      "fiesta          0.226396\n",
      "cuarentena      0.201604\n",
      "bailar          0.148530\n",
      "noche           0.143307\n",
      "salir cantar    0.136273\n",
      "así             0.131954\n",
      "aplauso         0.121063\n",
      "Name: 13, dtype: float64\n",
      "\n",
      "\n",
      "For topic 14 the words with the highest value are:\n",
      "mañana          2.229032\n",
      "escuchar        0.159504\n",
      "vez             0.127636\n",
      "mañana poner    0.120983\n",
      "tarde           0.097005\n",
      "hoy mañana      0.096661\n",
      "llevar          0.096295\n",
      "mismo           0.096281\n",
      "mañana salir    0.081775\n",
      "bien            0.080525\n",
      "Name: 14, dtype: float64\n",
      "\n",
      "\n",
      "For topic 15 the words with the highest value are:\n",
      "ventana             2.279715\n",
      "terraza             0.277529\n",
      "ver ventana         0.181733\n",
      "vía                 0.162359\n",
      "noche               0.157333\n",
      "salir ventana       0.156927\n",
      "domingo             0.124879\n",
      "ventana aplaudir    0.116421\n",
      "terrazar            0.106005\n",
      "ventana terraza     0.104082\n",
      "Name: 15, dtype: float64\n",
      "\n",
      "\n",
      "For topic 16 the words with the highest value are:\n",
      "foto                           0.881821\n",
      "acabar                         0.759261\n",
      "segoviano                      0.688245\n",
      "periódico digital              0.673066\n",
      "segoviano periódico            0.673066\n",
      "segoviano periódico digital    0.673066\n",
      "periódico                      0.670521\n",
      "digital                        0.651397\n",
      "acabar publicar                0.608781\n",
      "acabar publicar foto           0.608781\n",
      "Name: 16, dtype: float64\n",
      "\n",
      "\n",
      "For topic 17 the words with the highest value are:\n",
      "gente          1.885308\n",
      "calle          1.419521\n",
      "pasar          0.227128\n",
      "mismo          0.213742\n",
      "gente salir    0.177994\n",
      "gritar         0.173472\n",
      "gente calle    0.159637\n",
      "perro          0.156974\n",
      "vivir          0.156419\n",
      "ver gente      0.155075\n",
      "Name: 17, dtype: float64\n",
      "\n",
      "\n",
      "For topic 18 the words with the highest value are:\n",
      "poder          1.758885\n",
      "sol            0.625986\n",
      "poder salir    0.436669\n",
      "tomar          0.396757\n",
      "tomar sol      0.264184\n",
      "poder hacer    0.166395\n",
      "esperar        0.130272\n",
      "hora           0.123856\n",
      "terraza        0.115307\n",
      "poder tirar    0.113801\n",
      "Name: 18, dtype: float64\n",
      "\n",
      "\n",
      "For topic 19 the words with the highest value are:\n",
      "spain           1.352510\n",
      "madrid          1.197447\n",
      "madrid spain    0.939692\n",
      "cuarentena      0.195255\n",
      "vez             0.128761\n",
      "cada            0.108715\n",
      "cada vez        0.107391\n",
      "ligar           0.098191\n",
      "semana          0.095789\n",
      "tarde           0.088261\n",
      "Name: 19, dtype: float64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for topic in range(components_df.shape[0]):\n",
    "    tmp = components_df.iloc[topic]\n",
    "    print(f'For topic {topic} the words with the highest value are:')\n",
    "    print(tmp.nlargest(10))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('balcony-models')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "10d25286d6d126a35d4ad4188b71370e978556e18398277650caecac83008c5a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
